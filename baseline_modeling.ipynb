{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "import ast\n",
    "import cv2\n",
    "import skimage\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #arr_0 is labels, arr_1 is images, arr_2 is hog features\n",
    "# with np.load('data.npz') as data:\n",
    "#     labels = data['arr_0']\n",
    "#     imgs = data['arr_1']\n",
    "#     hog_feats = data['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arr_0 is labels, arr_1 is images, arr_2 is hog features\n",
    "with np.load('data (1).npz') as data:\n",
    "    labels = data['arr_0']\n",
    "    imgs = data['arr_1']\n",
    "    hog_feats = data['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 128, 128)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 128, 128)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 16384)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_feats = hog_feats.reshape(hog_feats.shape[0],hog_feats.shape[1]*hog_feats.shape[2])\n",
    "hog_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_hog_features(data):\n",
    "#     num_samples = data.shape[0]\n",
    "#     hog_features = []\n",
    "#     for i in range(num_samples):\n",
    "#         img = data[i]\n",
    "#         feature = hog(img, orientations=9, pixels_per_cell=(4, 4), cells_per_block=(3, 3))\n",
    "#         hog_features.append(feature)\n",
    "#     return np.array(hog_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 16384)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = imgs.reshape(imgs.shape[0],imgs.shape[1]*imgs.shape[2])\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split train and test\n",
    "# x_train,x_test,y_train,y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample to fix class imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = MLPClassifier(solver ='adam',\n",
    "#                    activation = 'relu',\n",
    "#                    alpha = 0.001,\n",
    "#                    hidden_layer_sizes = (512,128,10),\n",
    "#                    random_state = 1,\n",
    "#                    max_iter = 100,\n",
    "#                    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_svc = SVC(kernel = 'rbf',\n",
    "#               class_weight = 'balanced',\n",
    "#               random_state = 1,\n",
    "#               max_iter = 20,\n",
    "#               verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_svc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_svc = clf_svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test,y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_feats = np.zeros(imgs.shape)\n",
    "for im in range(0,imgs.shape[0]):\n",
    "    edges = cv2.Canny(np.uint8(imgs[im]*255),100,200)\n",
    "    canny_feats[im,:,:] = edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 128, 128)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canny_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 16384)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canny_ = canny_feats.reshape(canny_feats.shape[0], canny_feats.shape[1]*canny_feats.shape[2])\n",
    "canny_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test HOG and Canny Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = np.concatenate([hog_feats,canny_], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features, labels = labels, model_type = 'mlp'):\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if model_type == 'mlp' or 'all':\n",
    "        clf = MLPClassifier(solver ='lbfgs',\n",
    "                       activation = 'relu',\n",
    "                       alpha = 50,\n",
    "                       hidden_layer_sizes = (256,128,5),\n",
    "                       random_state = 1,\n",
    "                       max_iter = 500,\n",
    "                       early_stopping = True,\n",
    "                       verbose = True)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print('-'*30)\n",
    "        print('MLP Results:')\n",
    "        print(classification_report(y_test,y_pred))\n",
    "    if model_type == 'all':\n",
    "        print('-'*30)\n",
    "        print('-'*30)\n",
    "    if model_type == 'svc' or 'all':\n",
    "        clf_svc = make_pipeline(StandardScaler(), SVC(kernel = 'rbf',\n",
    "#                   class_weight = 'balanced',\n",
    "                  random_state = 1,\n",
    "                  max_iter = 100,\n",
    "                  verbose = True))\n",
    "        clf_svc.fit(x_train,y_train)\n",
    "        y_pred_svc = clf_svc.predict(x_test)\n",
    "        print('SVC Results:')\n",
    "        print(classification_report(y_test,y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MLP Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.42      0.35       156\n",
      "          17       0.00      0.00      0.00        89\n",
      "          18       0.22      0.13      0.16        87\n",
      "          27       0.40      0.51      0.45       140\n",
      "          64       0.37      0.46      0.41       122\n",
      "\n",
      "    accuracy                           0.34       594\n",
      "   macro avg       0.26      0.30      0.27       594\n",
      "weighted avg       0.28      0.34      0.31       594\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.13      0.19       156\n",
      "          17       0.31      0.16      0.21        89\n",
      "          18       0.36      0.29      0.32        87\n",
      "          27       0.50      0.02      0.04       140\n",
      "          64       0.24      0.81      0.37       122\n",
      "\n",
      "    accuracy                           0.27       594\n",
      "   macro avg       0.35      0.28      0.23       594\n",
      "weighted avg       0.35      0.27      0.21       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hog features\n",
    "train_model(hog_feats, model_type = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MLP Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.22      0.28       156\n",
      "          17       0.00      0.00      0.00        89\n",
      "          18       0.26      0.37      0.30        87\n",
      "          27       0.40      0.37      0.39       140\n",
      "          64       0.26      0.52      0.34       122\n",
      "\n",
      "    accuracy                           0.31       594\n",
      "   macro avg       0.26      0.30      0.26       594\n",
      "weighted avg       0.29      0.31      0.28       594\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.21      0.21       156\n",
      "          17       0.24      0.19      0.21        89\n",
      "          18       0.19      0.16      0.17        87\n",
      "          27       0.30      0.20      0.24       140\n",
      "          64       0.20      0.34      0.25       122\n",
      "\n",
      "    accuracy                           0.22       594\n",
      "   macro avg       0.23      0.22      0.22       594\n",
      "weighted avg       0.23      0.22      0.22       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#canny features\n",
    "train_model(canny_, model_type = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "MLP Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.28      0.28       156\n",
      "          17       0.24      0.20      0.22        89\n",
      "          18       0.22      0.11      0.15        87\n",
      "          27       0.37      0.30      0.33       140\n",
      "          64       0.24      0.40      0.30       122\n",
      "\n",
      "    accuracy                           0.27       594\n",
      "   macro avg       0.27      0.26      0.26       594\n",
      "weighted avg       0.28      0.27      0.27       594\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Courtney/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.32      0.33       156\n",
      "          17       0.31      0.30      0.31        89\n",
      "          18       0.31      0.22      0.26        87\n",
      "          27       0.13      0.01      0.03       140\n",
      "          64       0.20      0.47      0.28       122\n",
      "\n",
      "    accuracy                           0.26       594\n",
      "   macro avg       0.26      0.26      0.24       594\n",
      "weighted avg       0.26      0.26      0.23       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#both hog + canny\n",
    "train_model(feats, model_type = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
